{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1686358d-e35c-4d36-9c69-d76492884bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29ceb05d990>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a06c480-70cd-4f71-9d6b-fcaa3cba165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upstream_gene(gene, weight, grn = grn, important_genes = important_genes):\n",
    "    upstream_genes = grn.iloc[np.where(grn[\"target\"] == gene)[0]][\"regulator\"]\n",
    "    if len(upstream_genes) == 0:\n",
    "        return -1\n",
    "    for i in range(len(upstream_genes)):\n",
    "        if upstream_genes.iloc[i] in important_genes.keys():\n",
    "            if weight <.001:\n",
    "                #print(\"weight too small\")\n",
    "                continue\n",
    "            else:\n",
    "                important_genes[upstream_genes.iloc[i]] = important_genes[upstream_genes.iloc[i]] + weight\n",
    "                #get_upstream_gene(upstream_genes.iloc[i], weight*.5, grn, important_genes)\n",
    "        elif \"HK\" in upstream_genes.iloc[i]:\n",
    "            continue\n",
    "        else:\n",
    "            if weight*.5 < .001:\n",
    "                #print(\"weight too small\")\n",
    "                continue\n",
    "            else:\n",
    "                get_upstream_gene(upstream_genes.iloc[i], weight*.5, grn, important_genes)\n",
    "\n",
    "def Calc_var_captured(genes = genes, strengths = strengths, important_genes = important_genes, grn = grn):\n",
    "    weight = 1\n",
    "    weights = np.abs(strengths) / sum(np.abs(strengths))\n",
    "    for i in range(len(genes)):\n",
    "        if genes[i] in important_genes.keys():\n",
    "            if weights[i] <.001:\n",
    "                #print(\"weight too small\")\n",
    "                continue\n",
    "            else:\n",
    "                important_genes[genes[i]] = important_genes[genes[i]] + weights[i]\n",
    "                #get_upstream_gene(genes[i], weights[i]*.5, grn, important_genes)\n",
    "        else:\n",
    "            if weights[i]*.5 < .001:\n",
    "                #print(\"weight too small\")\n",
    "                continue\n",
    "            else:\n",
    "                get_upstream_gene(genes[i], weights[i]*.5, grn, important_genes)\n",
    "        #print(genes[i], \"\\n\", important_genes, \"\\n\")\n",
    "    print(sum(important_genes.values()))\n",
    "    print(important_genes)\n",
    "    \n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "224839ec-fb80-4412-bbb8-220a5ccea5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "test_data = test_data.drop(\"Unnamed: 0\", axis = 1)\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "train_data = train_data.drop(\"Unnamed: 0\", axis = 1)\n",
    "\n",
    "test_data_X = test_data.drop(\"time\", axis = 1)\n",
    "test_data_y = test_data[\"time\"]\n",
    "train_data_X = train_data.drop(\"time\", axis = 1)\n",
    "train_data_y = train_data[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d69bf9e4-25af-433d-a71e-847e4f000d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynGenData():\n",
    "    def __init__(self, mode):\n",
    "        if mode == \"train\":\n",
    "            self.x = torch.from_numpy(train_data_X.to_numpy())\n",
    "            self.y = torch.from_numpy(train_data_y.to_numpy())\n",
    "            self.n_samples = train_data_y.to_numpy().shape[0]\n",
    "        elif mode == \"test\":\n",
    "            self.x = torch.from_numpy(test_data_X.to_numpy())\n",
    "            self.y = torch.from_numpy(test_data_y.to_numpy())\n",
    "            self.n_samples = test_data_y.to_numpy().shape[0]\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size_1, hidden_size_2 = 50):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(train_data_X.shape[1], hidden_size_1)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.fc3 = nn.Linear(hidden_size_2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = self.fc2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "train_dataset = DynGenData(\"train\")\n",
    "test_dataset = DynGenData(\"test\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7169803c-3122-486b-b9a2-b6054dce7947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate is...  0.0001  hidden size is...  750 lambda 1 is...  0.0001 lambda 2 is...  0\n",
      "Epoch [1/300], Step [22/22], Loss: 52131.5312\n",
      "Epoch [11/300], Step [22/22], Loss: 30922.5000\n",
      "Epoch [21/300], Step [22/22], Loss: 28066.8730\n",
      "Epoch [31/300], Step [22/22], Loss: 24512.5527\n",
      "Epoch [41/300], Step [22/22], Loss: 21881.3496\n",
      "Epoch [51/300], Step [22/22], Loss: 21080.1543\n",
      "Epoch [61/300], Step [22/22], Loss: 20937.0215\n",
      "Epoch [71/300], Step [22/22], Loss: 20878.5352\n",
      "Epoch [81/300], Step [22/22], Loss: 20840.0840\n",
      "Epoch [91/300], Step [22/22], Loss: 20813.0723\n",
      "Epoch [101/300], Step [22/22], Loss: 20793.9219\n",
      "Epoch [111/300], Step [22/22], Loss: 20780.1758\n",
      "Epoch [121/300], Step [22/22], Loss: 20770.1406\n",
      "Epoch [131/300], Step [22/22], Loss: 20763.2520\n",
      "Epoch [141/300], Step [22/22], Loss: 20758.4941\n",
      "Epoch [151/300], Step [22/22], Loss: 20755.4375\n",
      "Epoch [161/300], Step [22/22], Loss: 20753.5566\n",
      "Epoch [171/300], Step [22/22], Loss: 20752.4414\n",
      "Epoch [181/300], Step [22/22], Loss: 20752.3496\n",
      "Epoch [191/300], Step [22/22], Loss: 20758.0527\n",
      "Epoch [201/300], Step [22/22], Loss: 20850.7012\n",
      "Epoch [211/300], Step [22/22], Loss: 20753.9727\n",
      "Epoch [221/300], Step [22/22], Loss: 20751.1934\n",
      "Epoch [231/300], Step [22/22], Loss: 20752.4883\n",
      "Epoch [241/300], Step [22/22], Loss: 20751.1172\n",
      "Epoch [251/300], Step [22/22], Loss: 20838.8281\n",
      "Epoch [261/300], Step [22/22], Loss: 20796.4297\n",
      "Epoch [271/300], Step [22/22], Loss: 20751.1035\n",
      "Epoch [281/300], Step [22/22], Loss: 20750.9043\n",
      "Epoch [291/300], Step [22/22], Loss: 20750.9277\n",
      "25066.6509765625 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [.0001] \n",
    "hidden_sizes = [750]\n",
    "l1_lambdas = [.0001]\n",
    "l2_lambdas = [0]\n",
    "num_epochs = 300\n",
    "input_size = train_data_X.shape[1]\n",
    "\n",
    "for l1_lambda in l1_lambdas:\n",
    "    for l2_lambda in l2_lambdas:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for learning_rate in learning_rates:\n",
    "                print(\"learning rate is... \", learning_rate, \" hidden size is... \", hidden_size, \"lambda 1 is... \", l1_lambda, \"lambda 2 is... \", l2_lambda)\n",
    "                total_step = len(train_loader)\n",
    "                model = Net(hidden_size).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n",
    "                for epoch in range(num_epochs):\n",
    "                    model.train()\n",
    "                    for i, (images, labels) in enumerate(train_loader):  \n",
    "                        images = images.to(device, dtype=torch.float)\n",
    "                        labels = labels.to(device, dtype=torch.float)\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        l1_norm = sum(torch.linalg.norm(p, 1) for p in model.parameters())\n",
    "                        loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "                        optimizer.zero_grad() \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    if epoch % 10 == 0:\n",
    "                        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "                with torch.no_grad(): # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "                    model.eval()\n",
    "                    mse = []\n",
    "                    for images, labels in test_loader:\n",
    "                        images = images.to(device, dtype=torch.float)\n",
    "                        labels = labels.to(device, dtype=torch.float)\n",
    "                        outputs = model(images)\n",
    "                        mse.append(criterion(outputs, labels).item())\n",
    "                print(np.mean(mse), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556cda1c-e7cb-4b85-af78-cc8845df66eb",
   "metadata": {},
   "source": [
    "## Calculate Neural Network variable importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c6496-0788-429c-a2df-d0951f5a6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# Get baseline model performance\n",
    "df_tensor = df_to_tensor(test_data_X)\n",
    "true_vals = df_to_tensor(test_data_y)\n",
    "baseline = torch.mean((model(df_tensor) - true_vals)**2).item()\n",
    "\n",
    "differences = []\n",
    "for i in test_data_X.columns:\n",
    "    temp = test_data_X.copy()\n",
    "    temp[i] = np.random.permutation(temp[i])\n",
    "    df_tensor = df_to_tensor(temp)\n",
    "    difference = baseline - torch.mean((model(df_tensor) - true_vals)**2).item()\n",
    "    differences.append(difference)\n",
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7c5f1645-c244-4a36-a2a2-edd95cab1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Target193', 'HK1998', 'Target672', 'HK2076', 'Target709', 'Target860',\n",
      "       'Target629', 'Target742', 'HK2104', 'Target823', 'HK3018', 'HK3160',\n",
      "       'HK836', 'HK552', 'HK2261', 'Target654', 'HK2375', 'HK939', 'HK1443',\n",
      "       'HK2752', 'HK3025', 'HK1711', 'HK2638', 'HK214', 'Target759'],\n",
      "      dtype='object')\n",
      "[-14.06054688 -13.19335938 -12.953125   -11.35546875  -9.74414062\n",
      "  -9.50195312  -9.49804688  -9.203125    -8.88671875  -8.79101562\n",
      "  -8.4140625   -8.33984375  -8.28125     -8.26757812  -8.1328125\n",
      "  -7.92773438  -7.67382812  -7.62304688  -7.61914062  -7.59179688\n",
      "  -7.4140625   -7.32617188  -7.265625    -7.23828125  -7.16992188]\n"
     ]
    }
   ],
   "source": [
    "genes = test_data_X.columns[np.array(differences).argsort()[:25]]\n",
    "strengths = np.array(differences)[np.array(differences).argsort()[:25]]\n",
    "print(genes)\n",
    "print(strengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e282bb-0454-4e92-9e0f-2361bb2b8441",
   "metadata": {},
   "source": [
    "# Compare Important Variables with Driving Genes\n",
    "The gene names and strengths for the Lasso and Random Forest were entered in manually by copying output from R.\n",
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "153629c6-e5e1-45a9-a145-3bc7301028ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27018913108077397\n",
      "{'A1_TF1': 0, 'A2_TF1': 0, 'A3_TF1': 0, 'A4_TF1': 0, 'B1_TF1': 0.046719047702284605, 'B2_TF1': 0.047588666118967296, 'B3_TF1': 0.050241220786939114, 'B4_TF1': 0, 'B5_TF1': 0, 'B6_TF1': 0, 'B7_TF1': 0, 'B8_TF1': 0, 'B9_TF1': 0, 'B10_TF1': 0, 'B11_TF1': 0.021251026936321207, 'B12_TF1': 0, 'B13_TF1': 0, 'B14_TF1': 0, 'Burn1_TF1': 0, 'Burn2_TF1': 0, 'Burn3_TF1': 0, 'Burn4_TF1': 0, 'C1_TF1': 0.01966910800748134, 'C2_TF1': 0, 'C3_TF1': 0.05326085056547047, 'C4_TF1': 0, 'D1_TF1': 0, 'D2_TF1': 0, 'D3_TF1': 0.03145921096330997, 'D4_TF1': 0, 'D5_TF1': 0}\n"
     ]
    }
   ],
   "source": [
    "genes = test_data_X.columns[np.array(differences).argsort()[:25]]\n",
    "strengths = np.array(differences)[np.array(differences).argsort()[:25]]\n",
    "\n",
    "important_genes = {\"A1_TF1\":0, \"A2_TF1\":0, \"A3_TF1\":0, \"A4_TF1\":0, \n",
    "                   \"B1_TF1\":0, \"B2_TF1\":0, \"B3_TF1\":0, \"B4_TF1\":0, \"B5_TF1\":0, \"B6_TF1\":0, \"B7_TF1\":0, \"B8_TF1\":0, \"B9_TF1\":0, \"B10_TF1\":0, \"B11_TF1\":0, \"B12_TF1\":0, \"B13_TF1\":0, \"B14_TF1\":0,\n",
    "                   \"Burn1_TF1\":0, \"Burn2_TF1\":0, \"Burn3_TF1\":0, \"Burn4_TF1\":0,\n",
    "                   \"C1_TF1\":0, \"C2_TF1\":0, \"C3_TF1\":0, \"C4_TF1\":0,\n",
    "                   \"D1_TF1\":0, \"D2_TF1\":0, \"D3_TF1\":0, \"D4_TF1\":0, \"D5_TF1\":0}\n",
    "\n",
    "Calc_var_captured(genes = genes, strengths = strengths, important_genes = important_genes, grn = grn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa205dd-c87e-4ba0-8d04-c7487e3ec125",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ffee72b-c5a5-46a4-884f-6c9c70e698cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49563377859444796\n",
      "{'A1_TF1': 0, 'A2_TF1': 0, 'A3_TF1': 0, 'A4_TF1': 0, 'B1_TF1': 0.013707231859771652, 'B2_TF1': 0.013000047377825211, 'B3_TF1': 0.14177612657476477, 'B4_TF1': 0, 'B5_TF1': 0, 'B6_TF1': 0.11739272835955214, 'B7_TF1': 0, 'B8_TF1': 0.01283028553383851, 'B9_TF1': 0, 'B10_TF1': 0, 'B11_TF1': 0, 'B12_TF1': 0, 'B13_TF1': 0.035974222706250586, 'B14_TF1': 0, 'Burn1_TF1': 0, 'Burn2_TF1': 0, 'Burn3_TF1': 0, 'Burn4_TF1': 0, 'C1_TF1': 0, 'C2_TF1': 0, 'C3_TF1': 0, 'C4_TF1': 0.060200186182330306, 'D1_TF1': 0.02747073793154258, 'D2_TF1': 0, 'D3_TF1': 0.07328221206857218, 'D4_TF1': 0, 'D5_TF1': 0}\n"
     ]
    }
   ],
   "source": [
    "grn = pd.read_csv(\"data_raw/b3_cellwise_grn.csv\")\n",
    "important_genes = {\"A1_TF1\":0, \"A2_TF1\":0, \"A3_TF1\":0, \"A4_TF1\":0, \n",
    "                   \"B1_TF1\":0, \"B2_TF1\":0, \"B3_TF1\":0, \"B4_TF1\":0, \"B5_TF1\":0, \"B6_TF1\":0, \"B7_TF1\":0, \"B8_TF1\":0, \"B9_TF1\":0, \"B10_TF1\":0, \"B11_TF1\":0, \"B12_TF1\":0, \"B13_TF1\":0, \"B14_TF1\":0,\n",
    "                   \"Burn1_TF1\":0, \"Burn2_TF1\":0, \"Burn3_TF1\":0, \"Burn4_TF1\":0,\n",
    "                   \"C1_TF1\":0, \"C2_TF1\":0, \"C3_TF1\":0, \"C4_TF1\":0,\n",
    "                   \"D1_TF1\":0, \"D2_TF1\":0, \"D3_TF1\":0, \"D4_TF1\":0, \"D5_TF1\":0}\n",
    "genes = [\"HK2477\", \"Target18\", \"Target473\", \"Target892\", \"Target325\", \"Target115\", \"Target918\", \"Target184\", \"Target440\", \"Target860\", \"Target241\", \"B13_TF1\", \"HK1464\", \"Target468\", \"Target923\", \n",
    "         \"Target875\", \"Target842\", \"HK3883\", \"Target442\", \"Target450\", \"Target574\", \"Target672\", \"Target102\", \"Target39\", \"Target715\"]\n",
    "strengths = [97.35434, 47.04507, 45.25426, 33.84109, 32.17078, 31.46609, 30.71390, 30.40129, 30.07492, 29.73931, 28.88838, 27.57796, 26.82258, 26.50961, 25.57203, 25.32590, 24.98265, 24.26942, \n",
    "             22.60229, 22.28934, 22.18656, -21.01602, 20.89633, 19.93176, 19.67148]\n",
    "\n",
    "Calc_var_captured(genes = genes, strengths = strengths, important_genes = important_genes, grn = grn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b29601-176e-45e1-8b41-819b6d34fce8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e7dc4783-9ce7-4325-a722-f01e5a6772b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7032289163699191\n",
      "{'A1_TF1': 0, 'A2_TF1': 0, 'A3_TF1': 0, 'A4_TF1': 0, 'B1_TF1': 0.005456961768851211, 'B2_TF1': 0.08833661851559546, 'B3_TF1': 0.0894465881099056, 'B4_TF1': 0, 'B5_TF1': 0, 'B6_TF1': 0.07298256138829275, 'B7_TF1': 0, 'B8_TF1': 0.15257082866450064, 'B9_TF1': 0.009620973339283023, 'B10_TF1': 0, 'B11_TF1': 0, 'B12_TF1': 0.007185923420100566, 'B13_TF1': 0, 'B14_TF1': 0, 'Burn1_TF1': 0, 'Burn2_TF1': 0, 'Burn3_TF1': 0, 'Burn4_TF1': 0, 'C1_TF1': 0.04825433680809178, 'C2_TF1': 0, 'C3_TF1': 0, 'C4_TF1': 0.03407733905633956, 'D1_TF1': 0.08860739328102112, 'D2_TF1': 0, 'D3_TF1': 0.10668939201793744, 'D4_TF1': 0, 'D5_TF1': 0}\n"
     ]
    }
   ],
   "source": [
    "genes = [\"Target39\", \"Target716\", \"Target375\", \"Target714\", \"Target715\", \"Target467\", \"Target351\", \"Target892\", \"Target468\", \"Target79\", \"Target34\", \"Target75\", \"Target102\", \"Target18\", \"Target310\", \n",
    "         \"Target107\", \"Target746\", \"Target360\", \"Target877\", \"Target741\", \"Target115\", \"Target747\", \"Target717\", \"Target106\", \"Target654\"]\n",
    "strengths = [3462669.8, 3344881.9, 2174365.2, 1981037.1, 1295888.4, 1060049.7, 1031058.0, 827125.3, 776734.8, 655976.6, 607313.8, 558519.3, 522553.2, 509298.8, 472516.3, 467724.3, 433526.0, 355922.9, \n",
    "             349477.5, 323801.4, 286571.8, 283175.5, 253112.5, 251063.2, 245893.5]\n",
    "important_genes = {\"A1_TF1\":0, \"A2_TF1\":0, \"A3_TF1\":0, \"A4_TF1\":0, \n",
    "                   \"B1_TF1\":0, \"B2_TF1\":0, \"B3_TF1\":0, \"B4_TF1\":0, \"B5_TF1\":0, \"B6_TF1\":0, \"B7_TF1\":0, \"B8_TF1\":0, \"B9_TF1\":0, \"B10_TF1\":0, \"B11_TF1\":0, \"B12_TF1\":0, \"B13_TF1\":0, \"B14_TF1\":0,\n",
    "                   \"Burn1_TF1\":0, \"Burn2_TF1\":0, \"Burn3_TF1\":0, \"Burn4_TF1\":0,\n",
    "                   \"C1_TF1\":0, \"C2_TF1\":0, \"C3_TF1\":0, \"C4_TF1\":0,\n",
    "                   \"D1_TF1\":0, \"D2_TF1\":0, \"D3_TF1\":0, \"D4_TF1\":0, \"D5_TF1\":0}\n",
    "\n",
    "Calc_var_captured(genes = genes, strengths = strengths, important_genes = important_genes, grn = grn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
